

# returns list of all data in memory or a generator if dataset is too large 
def load_train_data():
    # TODO should return a list of tokenized sentences
    # TODO remove stop words
    return None, None

def load_test_data():
    # TODO should return a list of tokenized sentences
    # TODO remove stop words 
    return None, None